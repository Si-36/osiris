#!/usr/bin/env python3
"""
Simple test for ShapeMemoryV2 - Focus on core functionality
"""

import asyncio
import numpy as np
import sys
import os
sys.path.insert(0, os.path.join(os.path.dirname(__file__), 'core', 'src'))

from aura_intelligence.memory.fastrp_embeddings import FastRPEmbedder, FastRPConfig
from aura_intelligence.memory.knn_index import KNNIndex, KNNConfig
from aura_intelligence.tda.models import BettiNumbers

async def test_shape_memory_core():
    """Test core ShapeMemoryV2 functionality"""
    
    print("üß™ Testing Shape Memory V2 Core Components")
    print("=" * 60)
    
    # Test 1: FastRP Embedder
    print("\n1Ô∏è‚É£ FastRP Embedder")
    print("-" * 30)
    
    config = FastRPConfig(embedding_dim=128, iterations=3)
    embedder = FastRPEmbedder(config)
    embedder.initialize()
    
    # Create test persistence diagram
    persistence_diagram = np.array([
        [0.0, 1.0],
        [0.1, 0.8],
        [0.2, 0.5]
    ])
    betti = BettiNumbers(b0=1, b1=0, b2=0)
    
    # Generate embedding
    embedding = embedder.embed_persistence_diagram(persistence_diagram, betti)
    print(f"‚úÖ Generated embedding shape: {embedding.shape}")
    print(f"   Min: {embedding.min():.3f}, Max: {embedding.max():.3f}")
    print(f"   Norm: {np.linalg.norm(embedding):.3f}")
    
    # Test 2: Batch embedding
    print("\n2Ô∏è‚É£ Batch Embedding")
    print("-" * 30)
    
    batch_diagrams = [np.random.rand(5, 2) for _ in range(10)]
    batch_betti = [BettiNumbers(b0=1, b1=i%2, b2=0) for i in range(10)]
    
    batch_embeddings = embedder.embed_batch(batch_diagrams, batch_betti)
    print(f"‚úÖ Batch embeddings shape: {batch_embeddings.shape}")
    
    # Test 3: KNN Index
    print("\n3Ô∏è‚É£ KNN Index")
    print("-" * 30)
    
    knn_config = KNNConfig(backend='sklearn', metric='cosine')
    knn_index = KNNIndex(128, knn_config)
    
    # Add embeddings to index
    ids = [f"mem_{i}" for i in range(10)]
    knn_index.add(batch_embeddings, ids)
    print(f"‚úÖ Added {len(ids)} embeddings to index")
    
    # Search for similar
    query = batch_embeddings[0]  # Use first as query
    results = knn_index.search(query, k=5)
    
    print(f"‚úÖ Found {len(results)} similar memories:")
    for mem_id, distance in results[:3]:
        print(f"   - {mem_id}: distance={distance:.3f}")
    
    # Test 4: Different topologies produce different embeddings
    print("\n4Ô∏è‚É£ Topology Discrimination")
    print("-" * 30)
    
    # Simple chain topology
    chain_diagram = np.array([[0, 1], [0.1, 0.9]])
    chain_betti = BettiNumbers(b0=1, b1=0, b2=0)
    chain_embedding = embedder.embed_persistence_diagram(chain_diagram, chain_betti)
    
    # Cycle topology
    cycle_diagram = np.array([[0, 1], [0.2, 0.8], [0.3, 0.7]])
    cycle_betti = BettiNumbers(b0=1, b1=1, b2=0)
    cycle_embedding = embedder.embed_persistence_diagram(cycle_diagram, cycle_betti)
    
    # Complex topology
    complex_diagram = np.array([[0, 1], [0.1, 0.9], [0.2, 0.8], [0.3, 0.6], [0.4, 0.5]])
    complex_betti = BettiNumbers(b0=2, b1=1, b2=0)
    complex_embedding = embedder.embed_persistence_diagram(complex_diagram, complex_betti)
    
    # Compare embeddings
    chain_cycle_sim = np.dot(chain_embedding, cycle_embedding) / (np.linalg.norm(chain_embedding) * np.linalg.norm(cycle_embedding))
    chain_complex_sim = np.dot(chain_embedding, complex_embedding) / (np.linalg.norm(chain_embedding) * np.linalg.norm(complex_embedding))
    cycle_complex_sim = np.dot(cycle_embedding, complex_embedding) / (np.linalg.norm(cycle_embedding) * np.linalg.norm(complex_embedding))
    
    print(f"‚úÖ Topology similarities (cosine):")
    print(f"   Chain vs Cycle: {chain_cycle_sim:.3f}")
    print(f"   Chain vs Complex: {chain_complex_sim:.3f}")
    print(f"   Cycle vs Complex: {cycle_complex_sim:.3f}")
    
    # Test 5: Performance
    print("\n5Ô∏è‚É£ Performance Test")
    print("-" * 30)
    
    import time
    
    # Generate 100 diagrams
    test_diagrams = [np.random.rand(20, 2) for _ in range(100)]
    test_betti = [BettiNumbers(b0=1, b1=i%3, b2=0) for i in range(100)]
    
    # Time batch processing
    start = time.time()
    test_embeddings = embedder.embed_batch(test_diagrams, test_betti)
    batch_time = (time.time() - start) * 1000
    
    print(f"‚úÖ Embedded 100 diagrams in {batch_time:.2f}ms")
    print(f"   Average: {batch_time/100:.2f}ms per diagram")
    
    # Time KNN search
    knn_index_large = KNNIndex(128, knn_config)
    knn_index_large.add(test_embeddings, [f"test_{i}" for i in range(100)])
    
    start = time.time()
    for _ in range(10):
        query = test_embeddings[np.random.randint(100)]
        results = knn_index_large.search(query, k=10)
    search_time = (time.time() - start) * 100  # Convert to ms
    
    print(f"‚úÖ 10 KNN searches in {search_time:.2f}ms")
    print(f"   Average: {search_time/10:.2f}ms per search")
    
    print("\n" + "=" * 60)
    print("‚úÖ All core ShapeMemoryV2 tests passed!")
    print("\nüìä Summary:")
    print("- FastRP embeddings working ‚úÖ")
    print("- KNN index working ‚úÖ")
    print("- Topology discrimination working ‚úÖ")
    print("- Performance acceptable ‚úÖ")


if __name__ == "__main__":
    asyncio.run(test_shape_memory_core())