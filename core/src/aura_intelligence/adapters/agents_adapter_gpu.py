"""
ðŸ¤– GPU-Accelerated Agents Adapter
=================================

Manages agent lifecycle with GPU acceleration for massive
multi-agent systems at scale.

Features:
- Parallel agent spawning
- GPU state synchronization
- Batch health monitoring
- Resource optimization
- Collective decision making
- High-speed message passing
"""

import asyncio
import torch
import numpy as np
from typing import Dict, Any, List, Optional, Set, Tuple, Callable, Type
from dataclasses import dataclass, field
import time
import uuid
import structlog
from prometheus_client import Histogram, Counter, Gauge
from datetime import datetime, timedelta
from enum import Enum

from .base_adapter import BaseAdapter, HealthStatus, HealthMetrics, ComponentMetadata
from ..agents.agent_core import AURAAgentCore, AURAAgentState
from ..agents.agent_templates import ObserverAgent, AnalystAgent, ExecutorAgent, CoordinatorAgent

logger = structlog.get_logger(__name__)

# Metrics
AGENT_SPAWN_TIME = Histogram(
    'agents_spawn_seconds',
    'Agent spawning time',
    ['agent_type', 'batch_size', 'backend']
)

AGENT_STATE_SYNC_TIME = Histogram(
    'agents_state_sync_seconds',
    'Agent state synchronization time',
    ['sync_type', 'num_agents', 'backend']
)

COLLECTIVE_DECISION_TIME = Histogram(
    'agents_collective_decision_seconds',
    'Collective decision making time',
    ['decision_type', 'num_agents']
)

ACTIVE_AGENTS = Gauge(
    'agents_active_total',
    'Number of active agents',
    ['agent_type']
)


class AgentStatus(Enum):
    """Agent lifecycle status"""
    INITIALIZING = "initializing"
    ACTIVE = "active"
    IDLE = "idle"
    BUSY = "busy"
    TERMINATING = "terminating"
    TERMINATED = "terminated"


@dataclass
class GPUAgentsConfig:
    """Configuration for GPU agents adapter"""
    # GPU settings
    use_gpu: bool = True
    gpu_device: int = 0
    
    # Agent management
    max_agents: int = 10000
    spawn_batch_size: int = 100
    state_sync_interval_ms: int = 100
    
    # Resource management
    gpu_memory_per_agent_mb: float = 10.0
    cpu_cores_per_agent: float = 0.1
    
    # Communication
    message_batch_size: int = 1000
    broadcast_chunk_size: int = 500
    
    # Collective reasoning
    voting_threshold: float = 0.6
    consensus_timeout_s: float = 5.0
    
    # Performance
    gpu_threshold: int = 10  # Use GPU for > this many agents


@dataclass
class AgentPool:
    """GPU-optimized agent pool"""
    def __init__(self, agent_type: str, capacity: int, device: torch.device):
        self.agent_type = agent_type
        self.capacity = capacity
        self.device = device
        
        # Agent tracking
        self.agents: Dict[str, AURAAgentCore] = {}
        self.agent_indices: Dict[str, int] = {}
        
        # GPU state tensors
        self.status_tensor = torch.zeros(capacity, dtype=torch.int32, device=device)
        self.health_scores = torch.ones(capacity, dtype=torch.float32, device=device)
        self.last_activity = torch.zeros(capacity, dtype=torch.float64, device=device)
        
        # Resource usage
        self.cpu_usage = torch.zeros(capacity, dtype=torch.float32, device=device)
        self.memory_usage = torch.zeros(capacity, dtype=torch.float32, device=device)
        
        # Communication buffers
        self.message_counts = torch.zeros(capacity, dtype=torch.int32, device=device)
        
    def add_agent(self, agent: AURAAgentCore) -> int:
        """Add agent to pool and return index"""
        for i in range(self.capacity):
            if self.status_tensor[i] == 0:  # Empty slot
                self.agents[agent.state.agent_id] = agent
                self.agent_indices[agent.state.agent_id] = i
                self.status_tensor[i] = AgentStatus.INITIALIZING.value
                self.last_activity[i] = time.time()
                return i
        raise RuntimeError("Agent pool at capacity")
        
    def remove_agent(self, agent_id: str) -> None:
        """Remove agent from pool"""
        if agent_id in self.agent_indices:
            idx = self.agent_indices[agent_id]
            self.status_tensor[idx] = 0
            del self.agents[agent_id]
            del self.agent_indices[agent_id]


class CollectiveReasoner:
    """GPU-accelerated collective reasoning"""
    
    def __init__(self, device: torch.device):
        self.device = device
        
    async def vote(self, 
                   votes: torch.Tensor,
                   weights: Optional[torch.Tensor] = None,
                   threshold: float = 0.5) -> Dict[str, Any]:
        """
        Perform weighted voting on GPU.
        
        Args:
            votes: Tensor of shape (num_agents, num_options)
            weights: Optional agent weights
            threshold: Acceptance threshold
        """
        if weights is None:
            weights = torch.ones(votes.shape[0], device=self.device)
            
        # Normalize weights
        weights = weights / weights.sum()
        
        # Weighted vote aggregation
        weighted_votes = votes * weights.unsqueeze(1)
        vote_totals = weighted_votes.sum(dim=0)
        
        # Find winning option
        winner_idx = torch.argmax(vote_totals)
        winner_score = vote_totals[winner_idx]
        
        # Check if threshold met
        consensus_reached = winner_score >= threshold
        
        return {
            'winner': int(winner_idx),
            'score': float(winner_score),
            'consensus': consensus_reached,
            'vote_distribution': vote_totals.cpu().numpy().tolist()
        }
        
    async def aggregate_beliefs(self,
                              beliefs: torch.Tensor,
                              confidence: torch.Tensor) -> torch.Tensor:
        """
        Aggregate agent beliefs weighted by confidence.
        
        Args:
            beliefs: Tensor of shape (num_agents, belief_dim)
            confidence: Tensor of shape (num_agents,)
        """
        # Normalize confidence scores
        weights = torch.softmax(confidence, dim=0)
        
        # Weighted belief aggregation
        aggregated = torch.sum(beliefs * weights.unsqueeze(1), dim=0)
        
        return aggregated


class GPUAgentsAdapter(BaseAdapter):
    """
    GPU-accelerated agent lifecycle management.
    
    Manages:
    - Agent spawning and termination
    - State synchronization
    - Resource allocation
    - Inter-agent communication
    - Collective decision making
    """
    
    def __init__(self, config: GPUAgentsConfig):
        super().__init__(
            component_id="agents_gpu",
            metadata=ComponentMetadata(
                version="2.0.0",
                capabilities=["parallel_spawn", "gpu_state_sync", "collective_reasoning"],
                dependencies={"agents_core", "torch"},
                tags=["gpu", "agents", "lifecycle", "production"]
            )
        )
        
        self.config = config
        
        # Initialize GPU
        if torch.cuda.is_available() and config.use_gpu:
            torch.cuda.set_device(config.gpu_device)
            self.device = torch.device(f"cuda:{config.gpu_device}")
            self.gpu_available = True
            logger.info(f"GPU Agents using CUDA device {config.gpu_device}")
        else:
            self.device = torch.device("cpu")
            self.gpu_available = False
            
        # Agent pools by type
        self.agent_pools: Dict[str, AgentPool] = {}
        
        # Collective reasoning
        self.collective_reasoner = CollectiveReasoner(self.device)
        
        # Message queues
        self.message_queues: Dict[str, List[Dict[str, Any]]] = {}
        self.message_lock = asyncio.Lock()
        
        # Background tasks
        self._state_sync_task = None
        self._health_monitor_task = None
        
    async def initialize(self) -> None:
        """Initialize GPU agents adapter"""
        await super().initialize()
        
        # Initialize agent pools
        agent_types = ["observer", "analyst", "executor", "coordinator"]
        for agent_type in agent_types:
            pool_capacity = self.config.max_agents // len(agent_types)
            self.agent_pools[agent_type] = AgentPool(
                agent_type, pool_capacity, self.device
            )
            
        # Start background tasks
        self._state_sync_task = asyncio.create_task(self._state_synchronizer())
        self._health_monitor_task = asyncio.create_task(self._health_monitor())
        
        logger.info("GPU Agents adapter initialized")
        
    async def spawn_agents(self,
                         agent_type: str,
                         count: int,
                         config: Optional[Dict[str, Any]] = None) -> List[str]:
        """
        Spawn multiple agents in parallel.
        """
        start_time = time.time()
        
        if agent_type not in self.agent_pools:
            raise ValueError(f"Unknown agent type: {agent_type}")
            
        pool = self.agent_pools[agent_type]
        
        # Determine backend
        use_gpu = (
            self.gpu_available and 
            count > self.config.gpu_threshold
        )
        
        try:
            if use_gpu:
                agent_ids = await self._spawn_agents_gpu(pool, agent_type, count, config)
            else:
                agent_ids = await self._spawn_agents_cpu(pool, agent_type, count, config)
                
            # Record metrics
            spawn_time = time.time() - start_time
            AGENT_SPAWN_TIME.labels(
                agent_type=agent_type,
                batch_size=count,
                backend='gpu' if use_gpu else 'cpu'
            ).observe(spawn_time)
            
            # Update active agent count
            ACTIVE_AGENTS.labels(agent_type=agent_type).set(len(pool.agents))
            
            logger.info(f"Spawned {len(agent_ids)} {agent_type} agents in {spawn_time:.3f}s")
            
            return agent_ids
            
        except Exception as e:
            logger.error(f"Agent spawning failed: {e}")
            raise
            
    async def _spawn_agents_gpu(self,
                              pool: AgentPool,
                              agent_type: str,
                              count: int,
                              config: Optional[Dict[str, Any]]) -> List[str]:
        """GPU-accelerated agent spawning"""
        
        agent_ids = []
        agents_to_spawn = []
        
        # Prepare agents
        agent_class = self._get_agent_class(agent_type)
        
        for i in range(count):
            agent_id = f"{agent_type}_{uuid.uuid4().hex[:8]}"
            agent = agent_class(agent_id=agent_id)
            
            # Configure agent
            if config:
                for key, value in config.items():
                    setattr(agent, key, value)
                    
            agents_to_spawn.append(agent)
            agent_ids.append(agent_id)
            
        # Batch initialization on GPU
        indices = []
        for agent in agents_to_spawn:
            idx = pool.add_agent(agent)
            indices.append(idx)
            
        # Update status tensor in batch
        indices_tensor = torch.tensor(indices, device=self.device)
        pool.status_tensor[indices_tensor] = AgentStatus.ACTIVE.value
        
        # Initialize agent components in parallel
        init_tasks = []
        for agent in agents_to_spawn:
            init_tasks.append(agent.initialize())
            
        await asyncio.gather(*init_tasks)
        
        return agent_ids
        
    async def _spawn_agents_cpu(self,
                              pool: AgentPool,
                              agent_type: str,
                              count: int,
                              config: Optional[Dict[str, Any]]) -> List[str]:
        """CPU fallback for agent spawning"""
        
        agent_ids = []
        agent_class = self._get_agent_class(agent_type)
        
        for i in range(count):
            agent_id = f"{agent_type}_{uuid.uuid4().hex[:8]}"
            agent = agent_class(agent_id=agent_id)
            
            if config:
                for key, value in config.items():
                    setattr(agent, key, value)
                    
            await agent.initialize()
            pool.add_agent(agent)
            agent_ids.append(agent_id)
            
        return agent_ids
        
    def _get_agent_class(self, agent_type: str) -> Type[AURAAgentCore]:
        """Get agent class by type"""
        classes = {
            "observer": ObserverAgent,
            "analyst": AnalystAgent,
            "executor": ExecutorAgent,
            "coordinator": CoordinatorAgent
        }
        return classes.get(agent_type, AURAAgentCore)
        
    async def terminate_agents(self,
                             agent_ids: List[str],
                             graceful: bool = True) -> Dict[str, Any]:
        """
        Terminate multiple agents.
        """
        terminated = []
        failed = []
        
        for agent_id in agent_ids:
            # Find agent in pools
            for pool in self.agent_pools.values():
                if agent_id in pool.agents:
                    agent = pool.agents[agent_id]
                    
                    try:
                        if graceful:
                            await agent.cleanup()
                            
                        pool.remove_agent(agent_id)
                        terminated.append(agent_id)
                        
                    except Exception as e:
                        logger.error(f"Failed to terminate {agent_id}: {e}")
                        failed.append(agent_id)
                        
                    break
                    
        # Update metrics
        for pool in self.agent_pools.values():
            ACTIVE_AGENTS.labels(agent_type=pool.agent_type).set(len(pool.agents))
            
        return {
            'terminated': terminated,
            'failed': failed,
            'graceful': graceful
        }
        
    async def sync_agent_states(self) -> Dict[str, Any]:
        """
        Synchronize agent states using GPU.
        """
        start_time = time.time()
        total_agents = sum(len(pool.agents) for pool in self.agent_pools.values())
        
        if not self.gpu_available or total_agents < self.config.gpu_threshold:
            return await self._sync_states_cpu()
            
        try:
            # Collect states from all pools
            all_states = []
            agent_map = {}
            
            for pool in self.agent_pools.values():
                for agent_id, agent in pool.agents.items():
                    idx = pool.agent_indices[agent_id]
                    state_dict = {
                        'agent_id': agent_id,
                        'status': pool.status_tensor[idx].item(),
                        'health': pool.health_scores[idx].item(),
                        'cpu_usage': pool.cpu_usage[idx].item(),
                        'memory_usage': pool.memory_usage[idx].item(),
                        'last_activity': pool.last_activity[idx].item()
                    }
                    all_states.append(state_dict)
                    agent_map[agent_id] = (pool, idx)
                    
            # GPU state aggregation
            # In real implementation, would perform complex state updates
            
            # Update agent internal states
            update_tasks = []
            for state_dict in all_states:
                agent_id = state_dict['agent_id']
                pool, idx = agent_map[agent_id]
                agent = pool.agents[agent_id]
                
                # Update agent with aggregated state
                update_tasks.append(self._update_agent_state(agent, state_dict))
                
            await asyncio.gather(*update_tasks)
            
            # Record metrics
            sync_time = time.time() - start_time
            AGENT_STATE_SYNC_TIME.labels(
                sync_type='full',
                num_agents=total_agents,
                backend='gpu'
            ).observe(sync_time)
            
            return {
                'synced': total_agents,
                'sync_time_ms': sync_time * 1000,
                'gpu_accelerated': True
            }
            
        except Exception as e:
            logger.error(f"GPU state sync failed: {e}")
            return await self._sync_states_cpu()
            
    async def _sync_states_cpu(self) -> Dict[str, Any]:
        """CPU fallback for state synchronization"""
        total_agents = sum(len(pool.agents) for pool in self.agent_pools.values())
        
        return {
            'synced': total_agents,
            'gpu_accelerated': False
        }
        
    async def _update_agent_state(self,
                                agent: AURAAgentCore,
                                state_dict: Dict[str, Any]) -> None:
        """Update individual agent state"""
        # In real implementation, would update agent's internal state
        pass
        
    async def broadcast_message(self,
                              message: Dict[str, Any],
                              agent_filter: Optional[Callable] = None) -> Dict[str, Any]:
        """
        Broadcast message to multiple agents.
        """
        if self.gpu_available:
            return await self._broadcast_gpu(message, agent_filter)
        else:
            return await self._broadcast_cpu(message, agent_filter)
            
    async def _broadcast_gpu(self,
                           message: Dict[str, Any],
                           agent_filter: Optional[Callable]) -> Dict[str, Any]:
        """GPU-accelerated message broadcast"""
        
        recipients = []
        
        # Filter agents using GPU
        for pool in self.agent_pools.values():
            if not pool.agents:
                continue
                
            # Apply filter on GPU
            if agent_filter:
                # Create mask based on filter
                mask = torch.ones(pool.capacity, dtype=torch.bool, device=self.device)
                
                for agent_id, idx in pool.agent_indices.items():
                    agent = pool.agents[agent_id]
                    if not agent_filter(agent):
                        mask[idx] = False
                        
                # Get filtered indices
                filtered_indices = torch.where(mask)[0]
                
                for idx in filtered_indices:
                    for agent_id, agent_idx in pool.agent_indices.items():
                        if agent_idx == idx.item():
                            recipients.append(agent_id)
                            break
            else:
                recipients.extend(pool.agents.keys())
                
        # Queue messages
        async with self.message_lock:
            for agent_id in recipients:
                if agent_id not in self.message_queues:
                    self.message_queues[agent_id] = []
                self.message_queues[agent_id].append(message)
                
        return {
            'recipients': len(recipients),
            'queued': True,
            'gpu_accelerated': True
        }
        
    async def _broadcast_cpu(self,
                           message: Dict[str, Any],
                           agent_filter: Optional[Callable]) -> Dict[str, Any]:
        """CPU fallback for message broadcast"""
        
        recipients = []
        
        for pool in self.agent_pools.values():
            for agent_id, agent in pool.agents.items():
                if not agent_filter or agent_filter(agent):
                    recipients.append(agent_id)
                    
        # Queue messages
        async with self.message_lock:
            for agent_id in recipients:
                if agent_id not in self.message_queues:
                    self.message_queues[agent_id] = []
                self.message_queues[agent_id].append(message)
                
        return {
            'recipients': len(recipients),
            'gpu_accelerated': False
        }
        
    async def collective_decision(self,
                                decision_type: str,
                                options: List[Any],
                                participating_agents: Optional[List[str]] = None) -> Dict[str, Any]:
        """
        Make collective decision using GPU voting.
        """
        start_time = time.time()
        
        # Collect votes from agents
        if participating_agents:
            agents = []
            for agent_id in participating_agents:
                for pool in self.agent_pools.values():
                    if agent_id in pool.agents:
                        agents.append(pool.agents[agent_id])
                        break
        else:
            agents = []
            for pool in self.agent_pools.values():
                agents.extend(pool.agents.values())
                
        if not agents:
            return {'error': 'No agents available'}
            
        # Collect votes (mock for demo)
        num_agents = len(agents)
        num_options = len(options)
        
        # Generate random votes on GPU
        votes = torch.rand(num_agents, num_options, device=self.device)
        
        # Agent confidence/expertise weights
        weights = torch.rand(num_agents, device=self.device) + 0.5
        
        # Perform collective reasoning
        result = await self.collective_reasoner.vote(
            votes, weights, self.config.voting_threshold
        )
        
        # Record metrics
        decision_time = time.time() - start_time
        COLLECTIVE_DECISION_TIME.labels(
            decision_type=decision_type,
            num_agents=num_agents
        ).observe(decision_time)
        
        result.update({
            'decision_type': decision_type,
            'num_agents': num_agents,
            'options': options,
            'selected_option': options[result['winner']],
            'decision_time_ms': decision_time * 1000
        })
        
        return result
        
    async def get_agent_metrics(self) -> Dict[str, Any]:
        """Get comprehensive agent metrics"""
        
        metrics = {
            'total_agents': 0,
            'by_type': {},
            'by_status': {},
            'resource_usage': {
                'total_cpu': 0.0,
                'total_memory_mb': 0.0,
                'gpu_memory_mb': 0.0
            }
        }
        
        # Aggregate metrics from pools
        for pool in self.agent_pools.values():
            num_agents = len(pool.agents)
            metrics['total_agents'] += num_agents
            metrics['by_type'][pool.agent_type] = num_agents
            
            if num_agents > 0 and self.gpu_available:
                # Get status distribution
                for status in AgentStatus:
                    count = int((pool.status_tensor == status.value).sum())
                    if status.name not in metrics['by_status']:
                        metrics['by_status'][status.name] = 0
                    metrics['by_status'][status.name] += count
                    
                # Resource usage
                metrics['resource_usage']['total_cpu'] += float(pool.cpu_usage.sum())
                metrics['resource_usage']['total_memory_mb'] += float(pool.memory_usage.sum())
                
        # GPU memory
        if self.gpu_available:
            metrics['resource_usage']['gpu_memory_mb'] = (
                torch.cuda.memory_allocated(self.config.gpu_device) / 1024 / 1024
            )
            
        return metrics
        
    async def _state_synchronizer(self):
        """Background state synchronization"""
        while True:
            try:
                await asyncio.sleep(self.config.state_sync_interval_ms / 1000.0)
                await self.sync_agent_states()
                
            except Exception as e:
                logger.error(f"State sync error: {e}")
                await asyncio.sleep(1)
                
    async def _health_monitor(self):
        """Background health monitoring"""
        while True:
            try:
                await asyncio.sleep(5)  # Every 5 seconds
                
                # Check agent health
                for pool in self.agent_pools.values():
                    if not pool.agents:
                        continue
                        
                    # Update health scores based on activity
                    current_time = time.time()
                    for agent_id, idx in pool.agent_indices.items():
                        last_activity = pool.last_activity[idx].item()
                        time_since_activity = current_time - last_activity
                        
                        # Degrade health for inactive agents
                        if time_since_activity > 60:  # 1 minute
                            pool.health_scores[idx] *= 0.95
                            
                        # Update resource usage (mock)
                        pool.cpu_usage[idx] = torch.rand(1, device=self.device) * 50
                        pool.memory_usage[idx] = torch.rand(1, device=self.device) * 100
                        
            except Exception as e:
                logger.error(f"Health monitor error: {e}")
                await asyncio.sleep(5)
                
    async def shutdown(self) -> None:
        """Shutdown adapter"""
        await super().shutdown()
        
        # Cancel background tasks
        for task in [self._state_sync_task, self._health_monitor_task]:
            if task:
                task.cancel()
                
        # Terminate all agents
        all_agent_ids = []
        for pool in self.agent_pools.values():
            all_agent_ids.extend(pool.agents.keys())
            
        if all_agent_ids:
            await self.terminate_agents(all_agent_ids, graceful=True)
            
        logger.info("GPU Agents adapter shut down")
        
    async def health(self) -> HealthMetrics:
        """Get adapter health"""
        metrics = HealthMetrics()
        
        try:
            if self.gpu_available:
                allocated = torch.cuda.memory_allocated(self.config.gpu_device)
                reserved = torch.cuda.memory_reserved(self.config.gpu_device)
                
                metrics.resource_usage["gpu_memory_allocated_mb"] = allocated / 1024 / 1024
                metrics.resource_usage["gpu_memory_reserved_mb"] = reserved / 1024 / 1024
                
            # Check agent pools
            total_agents = sum(len(pool.agents) for pool in self.agent_pools.values())
            metrics.resource_usage["total_agents"] = total_agents
            
            # Check message queues
            total_messages = sum(len(queue) for queue in self.message_queues.values())
            metrics.resource_usage["queued_messages"] = total_messages
            
            if total_messages > 10000:
                metrics.status = HealthStatus.DEGRADED
                metrics.failure_predictions.append("Message queue backlog")
            else:
                metrics.status = HealthStatus.HEALTHY
                
        except Exception as e:
            metrics.status = HealthStatus.UNHEALTHY
            metrics.failure_predictions.append(f"Health check failed: {e}")
            
        return metrics


# Factory function
def create_gpu_agents_adapter(
    use_gpu: bool = True,
    max_agents: int = 10000
) -> GPUAgentsAdapter:
    """Create GPU agents adapter"""
    
    config = GPUAgentsConfig(
        use_gpu=use_gpu,
        max_agents=max_agents,
        spawn_batch_size=100,
        gpu_threshold=10
    )
    
    return GPUAgentsAdapter(config)