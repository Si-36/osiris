"""
Orchestrator for Collective Intelligence - 2025 Production Implementation

Features:
- Multi-agent coordination
- Dynamic task allocation
- Collective decision making
- Real-time adaptation
- Fault tolerance and recovery
"""

import asyncio
from typing import Dict, Any, List, Optional, Set, Callable
from dataclasses import dataclass, field
from datetime import datetime
from enum import Enum
import structlog
import uuid

from .context_engine import ContextEngine, ContextScope, Evidence, EvidenceType
from .graph_builder import CollectiveGraphBuilder, GraphType, create_supervisor_graph
from .memory_manager import CollectiveMemoryManager, MemoryType, MemoryPriority

logger = structlog.get_logger(__name__)


class OrchestratorMode(Enum):
    """Operating modes for the orchestrator"""
    CENTRALIZED = "centralized"      # Single point of control
    DISTRIBUTED = "distributed"      # Peer-to-peer coordination
    HIERARCHICAL = "hierarchical"    # Multi-level hierarchy
    SWARM = "swarm"                 # Emergent behavior
    HYBRID = "hybrid"               # Adaptive mode switching


@dataclass
class CollectiveInsight:
    """Insight generated by the collective"""
    id: str = field(default_factory=lambda: f"insight_{uuid.uuid4().hex[:8]}")
    content: Dict[str, Any] = field(default_factory=dict)
    confidence: float = 0.0
    supporting_evidence: List[str] = field(default_factory=list)
    contributing_agents: List[str] = field(default_factory=list)
    timestamp: datetime = field(default_factory=datetime.now)
    insight_type: str = "general"
    metadata: Dict[str, Any] = field(default_factory=dict)


@dataclass
class AgentCapability:
    """Capability profile of an agent"""
    agent_id: str
    capabilities: Set[str]
    performance_score: float = 1.0
    availability: float = 1.0
    specializations: List[str] = field(default_factory=list)
    current_load: float = 0.0
    
    def can_handle(self, task_type: str) -> bool:
        """Check if agent can handle task type"""
        return task_type in self.capabilities or task_type in self.specializations
    
    def get_suitability_score(self, task_type: str) -> float:
        """Calculate suitability score for task"""
        base_score = 0.0
        
        if task_type in self.specializations:
            base_score = 1.0
        elif task_type in self.capabilities:
            base_score = 0.7
        
        # Adjust for performance and availability
        score = base_score * self.performance_score * self.availability
        
        # Penalize for high load
        score *= (1.0 - self.current_load * 0.5)
        
        return score


class CollectiveOrchestrator:
    """
    Advanced orchestrator for collective intelligence systems
    
    Key features:
    - Dynamic agent coordination
    - Collective decision making
    - Adaptive task allocation
    - Real-time performance monitoring
    - Fault tolerance
    """
    
    def __init__(self,
                 mode: OrchestratorMode = OrchestratorMode.HYBRID,
                 consensus_threshold: float = 0.66,
                 adaptation_rate: float = 0.1):
        self.mode = mode
        self.consensus_threshold = consensus_threshold
        self.adaptation_rate = adaptation_rate
        
        # Core components
        self.context_engine = ContextEngine()
        self.memory_manager = CollectiveMemoryManager()
        self.graph_builder = CollectiveGraphBuilder(GraphType.WORKFLOW)
        
        # Agent registry
        self.agents: Dict[str, AgentCapability] = {}
        self.active_tasks: Dict[str, Dict[str, Any]] = {}
        
        # Performance tracking
        self.agent_performance: Dict[str, List[float]] = {}
        self.task_history: List[Dict[str, Any]] = []
        
        # Coordination state
        self._initialized = False
        self._coordination_task: Optional[asyncio.Task] = None
        
        logger.info("Collective orchestrator created", mode=mode.value)
    
    async def initialize(self):
        """Initialize the orchestrator"""
        if self._initialized:
            logger.warning("Orchestrator already initialized")
            return
            
        logger.info("Initializing Collective Intelligence Orchestrator")
        
        # Start core components
        await self.memory_manager.start()
        
        # Start coordination loop
        self._coordination_task = asyncio.create_task(self._coordination_loop())
        
        self._initialized = True
        logger.info("Orchestrator initialization complete")
    
    async def shutdown(self):
        """Shutdown the orchestrator"""
        logger.info("Shutting down orchestrator")
        
        # Stop coordination
        if self._coordination_task:
            self._coordination_task.cancel()
            try:
                await self._coordination_task
            except asyncio.CancelledError:
                pass
        
        # Stop components
        await self.memory_manager.stop()
        
        self._initialized = False
        logger.info("Orchestrator shutdown complete")
    
    def register_agent(self,
                      agent_id: str,
                      capabilities: Set[str],
                      specializations: Optional[List[str]] = None) -> bool:
        """Register an agent with the collective"""
        if agent_id in self.agents:
            logger.warning("Agent already registered", agent=agent_id)
            return False
        
        self.agents[agent_id] = AgentCapability(
            agent_id=agent_id,
            capabilities=capabilities,
            specializations=specializations or []
        )
        
        self.agent_performance[agent_id] = []
        
        logger.info("Agent registered",
                   agent=agent_id,
                   capabilities=list(capabilities))
        
        return True
    
    async def gather_insights(self, 
                            context: Dict[str, Any]) -> CollectiveInsight:
        """Gather insights from the collective"""
        if not self._initialized:
            raise RuntimeError("Orchestrator not initialized")
        
        logger.info("Gathering collective insights", context_keys=list(context.keys()))
        
        # Store context in collective memory
        context_id = await self.memory_manager.store(
            content=context,
            agent_id="orchestrator",
            memory_type=MemoryType.WORKING,
            priority=MemoryPriority.HIGH
        )
        
        # Add context as evidence
        evidence = Evidence(
            type=EvidenceType.OBSERVATION,
            source="orchestrator",
            content=context,
            confidence=1.0
        )
        await self.context_engine.add_evidence(evidence, ContextScope.GLOBAL)
        
        # Determine task allocation based on mode
        if self.mode == OrchestratorMode.CENTRALIZED:
            insight = await self._centralized_gathering(context)
        elif self.mode == OrchestratorMode.DISTRIBUTED:
            insight = await self._distributed_gathering(context)
        elif self.mode == OrchestratorMode.SWARM:
            insight = await self._swarm_gathering(context)
        else:  # HYBRID or HIERARCHICAL
            insight = await self._hybrid_gathering(context)
        
        # Store insight in memory
        await self.memory_manager.store(
            content=insight.content,
            agent_id="orchestrator",
            memory_type=MemoryType.SEMANTIC,
            priority=MemoryPriority.HIGH,
            linked_to=[context_id]
        )
        
        # Add insight as evidence
        insight_evidence = Evidence(
            type=EvidenceType.INFERENCE,
            source="collective",
            content=insight.content,
            confidence=insight.confidence,
            causal_links=[evidence.id]
        )
        await self.context_engine.add_evidence(insight_evidence, ContextScope.GLOBAL)
        
        return insight
    
    async def allocate_task(self,
                           task: Dict[str, Any]) -> Optional[str]:
        """Allocate task to most suitable agent"""
        task_type = task.get("type", "general")
        task_priority = task.get("priority", 1.0)
        
        # Find suitable agents
        candidates = []
        for agent in self.agents.values():
            if agent.can_handle(task_type):
                score = agent.get_suitability_score(task_type)
                if score > 0:
                    candidates.append((score, agent))
        
        if not candidates:
            logger.warning("No suitable agent for task", task_type=task_type)
            return None
        
        # Sort by suitability
        candidates.sort(key=lambda x: x[0], reverse=True)
        
        # Select best agent
        selected_agent = candidates[0][1]
        
        # Update agent load
        selected_agent.current_load = min(1.0, selected_agent.current_load + 0.1)
        
        # Track task
        task_id = f"task_{uuid.uuid4().hex[:8]}"
        self.active_tasks[task_id] = {
            "task": task,
            "agent": selected_agent.agent_id,
            "start_time": datetime.now(),
            "status": "allocated"
        }
        
        logger.info("Task allocated",
                   task_id=task_id,
                   agent=selected_agent.agent_id,
                   score=candidates[0][0])
        
        return selected_agent.agent_id
    
    async def update_agent_performance(self,
                                     agent_id: str,
                                     task_id: str,
                                     success: bool,
                                     metrics: Optional[Dict[str, float]] = None):
        """Update agent performance based on task outcome"""
        if agent_id not in self.agents:
            return
        
        agent = self.agents[agent_id]
        
        # Calculate performance score
        score = 1.0 if success else 0.0
        
        # Adjust based on metrics
        if metrics:
            if "quality" in metrics:
                score *= metrics["quality"]
            if "efficiency" in metrics:
                score *= metrics["efficiency"]
        
        # Update performance history
        self.agent_performance[agent_id].append(score)
        
        # Keep only recent history
        if len(self.agent_performance[agent_id]) > 100:
            self.agent_performance[agent_id] = self.agent_performance[agent_id][-100:]
        
        # Update agent performance score (exponential moving average)
        history = self.agent_performance[agent_id]
        if len(history) >= 5:
            recent_avg = sum(history[-5:]) / 5
            agent.performance_score = (
                agent.performance_score * (1 - self.adaptation_rate) +
                recent_avg * self.adaptation_rate
            )
        
        # Update agent load
        agent.current_load = max(0.0, agent.current_load - 0.1)
        
        # Update task status
        if task_id in self.active_tasks:
            self.active_tasks[task_id]["status"] = "completed" if success else "failed"
            self.active_tasks[task_id]["end_time"] = datetime.now()
            
            # Move to history
            self.task_history.append(self.active_tasks[task_id])
            del self.active_tasks[task_id]
        
        logger.info("Agent performance updated",
                   agent=agent_id,
                   success=success,
                   new_score=agent.performance_score)
    
    async def _centralized_gathering(self, context: Dict[str, Any]) -> CollectiveInsight:
        """Centralized insight gathering (orchestrator decides)"""
        # Select best agents for the task
        task_type = context.get("task_type", "analysis")
        
        selected_agents = []
        for agent in sorted(
            self.agents.values(),
            key=lambda a: a.get_suitability_score(task_type),
            reverse=True
        )[:3]:  # Top 3 agents
            if agent.can_handle(task_type):
                selected_agents.append(agent.agent_id)
        
        # Simulate agent processing (in production, actual agent calls)
        agent_results = {}
        for agent_id in selected_agents:
            # Agent would process context and return result
            agent_results[agent_id] = {
                "insight": f"Analysis from {agent_id}",
                "confidence": 0.8 + (self.agents[agent_id].performance_score * 0.2)
            }
        
        # Aggregate results
        combined_confidence = sum(r["confidence"] for r in agent_results.values()) / len(agent_results)
        
        insight = CollectiveInsight(
            content={
                "summary": "Centralized analysis complete",
                "agent_insights": agent_results,
                "context": context
            },
            confidence=combined_confidence,
            contributing_agents=selected_agents,
            insight_type="centralized"
        )
        
        return insight
    
    async def _distributed_gathering(self, context: Dict[str, Any]) -> CollectiveInsight:
        """Distributed insight gathering (peer-to-peer)"""
        # All capable agents participate
        participating_agents = []
        
        for agent in self.agents.values():
            if agent.availability > 0.5:  # Available agents
                participating_agents.append(agent.agent_id)
        
        # Simulate distributed processing
        agent_votes = {}
        for agent_id in participating_agents:
            # Each agent votes on insight
            agent_votes[agent_id] = {
                "proposal": f"Distributed insight from {agent_id}",
                "weight": self.agents[agent_id].performance_score
            }
        
        # Build consensus
        consensus_result = await self._build_consensus(agent_votes)
        
        insight = CollectiveInsight(
            content={
                "consensus": consensus_result,
                "votes": len(agent_votes),
                "context": context
            },
            confidence=consensus_result["confidence"],
            contributing_agents=participating_agents,
            insight_type="distributed"
        )
        
        return insight
    
    async def _swarm_gathering(self, context: Dict[str, Any]) -> CollectiveInsight:
        """Swarm-based insight gathering (emergent behavior)"""
        # Agents self-organize based on local information
        swarm_clusters = self._form_swarm_clusters(context)
        
        cluster_insights = []
        
        for cluster in swarm_clusters:
            # Each cluster produces insight
            cluster_insight = {
                "agents": cluster,
                "pattern": f"Emergent pattern from {len(cluster)} agents",
                "strength": len(cluster) / len(self.agents)
            }
            cluster_insights.append(cluster_insight)
        
        # Merge cluster insights
        merged_confidence = sum(c["strength"] for c in cluster_insights) / len(cluster_insights)
        
        insight = CollectiveInsight(
            content={
                "clusters": cluster_insights,
                "emergence_level": len(swarm_clusters),
                "context": context
            },
            confidence=merged_confidence,
            contributing_agents=[a for c in swarm_clusters for a in c],
            insight_type="swarm"
        )
        
        return insight
    
    async def _hybrid_gathering(self, context: Dict[str, Any]) -> CollectiveInsight:
        """Hybrid gathering (adaptive mode selection)"""
        # Analyze context to determine best approach
        urgency = context.get("urgency", 0.5)
        complexity = context.get("complexity", 0.5)
        
        # Select mode based on context
        if urgency > 0.8:
            # High urgency - use centralized for speed
            return await self._centralized_gathering(context)
        elif complexity > 0.8:
            # High complexity - use distributed for thoroughness
            return await self._distributed_gathering(context)
        else:
            # Default - use swarm for emergence
            return await self._swarm_gathering(context)
    
    async def _build_consensus(self, agent_votes: Dict[str, Dict[str, Any]]) -> Dict[str, Any]:
        """Build consensus from agent votes"""
        if not agent_votes:
            return {"consensus": None, "confidence": 0.0}
        
        # Weight votes by agent performance
        weighted_votes = {}
        total_weight = 0.0
        
        for agent_id, vote in agent_votes.items():
            weight = vote.get("weight", 1.0)
            proposal = vote.get("proposal", "")
            
            if proposal not in weighted_votes:
                weighted_votes[proposal] = 0.0
            
            weighted_votes[proposal] += weight
            total_weight += weight
        
        # Find majority proposal
        if total_weight == 0:
            return {"consensus": None, "confidence": 0.0}
        
        best_proposal = max(weighted_votes.items(), key=lambda x: x[1])
        confidence = best_proposal[1] / total_weight
        
        # Check if consensus threshold met
        if confidence >= self.consensus_threshold:
            return {
                "consensus": best_proposal[0],
                "confidence": confidence,
                "support": best_proposal[1],
                "total_weight": total_weight
            }
        
        return {
            "consensus": None,
            "confidence": confidence,
            "proposals": weighted_votes
        }
    
    def _form_swarm_clusters(self, context: Dict[str, Any]) -> List[List[str]]:
        """Form agent clusters based on capabilities and context"""
        clusters = []
        assigned = set()
        
        # Group by primary capability relevant to context
        task_type = context.get("task_type", "general")
        
        for agent in self.agents.values():
            if agent.agent_id in assigned:
                continue
            
            if agent.can_handle(task_type):
                # Start new cluster
                cluster = [agent.agent_id]
                assigned.add(agent.agent_id)
                
                # Find similar agents
                for other in self.agents.values():
                    if (other.agent_id not in assigned and
                        other.can_handle(task_type) and
                        self._calculate_agent_similarity(agent, other) > 0.7):
                        cluster.append(other.agent_id)
                        assigned.add(other.agent_id)
                
                clusters.append(cluster)
        
        # Add unassigned agents as single clusters
        for agent_id in self.agents:
            if agent_id not in assigned:
                clusters.append([agent_id])
        
        return clusters
    
    def _calculate_agent_similarity(self,
                                  agent1: AgentCapability,
                                  agent2: AgentCapability) -> float:
        """Calculate similarity between agents"""
        # Capability overlap
        cap_overlap = len(agent1.capabilities & agent2.capabilities)
        cap_union = len(agent1.capabilities | agent2.capabilities)
        
        if cap_union == 0:
            return 0.0
        
        capability_sim = cap_overlap / cap_union
        
        # Performance similarity
        perf_sim = 1.0 - abs(agent1.performance_score - agent2.performance_score)
        
        # Combined similarity
        return 0.7 * capability_sim + 0.3 * perf_sim
    
    async def _coordination_loop(self):
        """Background coordination and adaptation"""
        while self._initialized:
            try:
                # Update agent availability based on load
                for agent in self.agents.values():
                    agent.availability = 1.0 - agent.current_load
                
                # Clean up old tasks
                cutoff_time = datetime.now().timestamp() - 3600  # 1 hour
                self.task_history = [
                    task for task in self.task_history
                    if task["start_time"].timestamp() > cutoff_time
                ]
                
                # Adapt mode if hybrid
                if self.mode == OrchestratorMode.HYBRID:
                    await self._adapt_mode()
                
                await asyncio.sleep(10)  # Run every 10 seconds
                
            except Exception as e:
                logger.error("Coordination loop error", error=str(e))
    
    async def _adapt_mode(self):
        """Adapt orchestration mode based on conditions"""
        # Analyze recent performance
        if not self.task_history:
            return
        
        recent_tasks = self.task_history[-20:]  # Last 20 tasks
        
        # Calculate metrics
        success_rate = sum(1 for t in recent_tasks if t["status"] == "completed") / len(recent_tasks)
        avg_agents = len(set(t["agent"] for t in recent_tasks)) / len(recent_tasks)
        
        # Adapt based on metrics
        if success_rate < 0.7:
            # Low success - switch to centralized
            self.mode = OrchestratorMode.CENTRALIZED
        elif avg_agents > 0.8 * len(self.agents):
            # High participation - switch to swarm
            self.mode = OrchestratorMode.SWARM
        else:
            # Normal - distributed
            self.mode = OrchestratorMode.DISTRIBUTED
        
        logger.debug("Mode adapted",
                    new_mode=self.mode.value,
                    success_rate=success_rate)


# Example usage
async def example_orchestrator_usage():
    """Example of using the collective orchestrator"""
    orchestrator = CollectiveOrchestrator()
    
    # Register agents
    orchestrator.register_agent(
        "analyzer_1",
        capabilities={"analysis", "pattern_recognition"},
        specializations=["anomaly_detection"]
    )
    
    orchestrator.register_agent(
        "predictor_1",
        capabilities={"prediction", "forecasting"},
        specializations=["time_series"]
    )
    
    orchestrator.register_agent(
        "optimizer_1",
        capabilities={"optimization", "planning"},
        specializations=["resource_allocation"]
    )
    
    # Initialize
    await orchestrator.initialize()
    
    try:
        # Gather insights
        context = {
            "task_type": "analysis",
            "data": {"temperature": 25.5, "trend": "rising"},
            "urgency": 0.6,
            "complexity": 0.7
        }
        
        insight = await orchestrator.gather_insights(context)
        print(f"Collective insight: {insight.content}")
        print(f"Confidence: {insight.confidence:.2%}")
        
        # Allocate task
        task = {
            "type": "anomaly_detection",
            "priority": 0.8,
            "data": context["data"]
        }
        
        assigned_agent = await orchestrator.allocate_task(task)
        print(f"Task assigned to: {assigned_agent}")
        
        # Simulate task completion
        await orchestrator.update_agent_performance(
            assigned_agent,
            "task_123",
            success=True,
            metrics={"quality": 0.95, "efficiency": 0.88}
        )
        
    finally:
        await orchestrator.shutdown()
    
    return orchestrator


if __name__ == "__main__":
    asyncio.run(example_orchestrator_usage())