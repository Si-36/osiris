"""
ðŸ§  LNN Council System - Extracted from 79 Files

Production-grade multi-agent neural decision making with:
- Liquid Neural Networks for adaptive learning
- Byzantine consensus for reliability
- Neural voting for collective decisions
- Transformer-based reasoning
- Real-time adaptation

This is the GOLD extracted from agents/council/lnn/!
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
from typing import Dict, Any, List, Optional, Tuple, AsyncIterator
from dataclasses import dataclass, field
from datetime import datetime, timezone
from enum import Enum
import asyncio
import numpy as np
import json
from uuid import UUID, uuid4
import structlog

logger = structlog.get_logger()


# ======================
# Data Contracts
# ======================

class VoteDecision(str, Enum):
    """Possible voting decisions"""
    APPROVE = "approve"
    REJECT = "reject"
    ABSTAIN = "abstain"
    DELEGATE = "delegate"
    ESCALATE = "escalate"


class VoteConfidence(float):
    """Vote confidence score between 0.0 and 1.0"""
    
    def __new__(cls, value: float):
        if not 0.0 <= value <= 1.0:
            raise ValueError(f"Confidence must be between 0.0 and 1.0, got {value}")
        return float.__new__(cls, value)


@dataclass(frozen=True)
class CouncilVote:
    """Individual agent vote"""
    agent_id: str
    decision: VoteDecision
    confidence: VoteConfidence
    reasoning: str
    evidence: List[Dict[str, Any]] = field(default_factory=list)
    timestamp: datetime = field(default_factory=lambda: datetime.now(timezone.utc))


@dataclass
class ConsensusResult:
    """Result of Byzantine consensus"""
    final_decision: VoteDecision
    consensus_confidence: float
    votes: List[CouncilVote]
    consensus_type: str  # "unanimous", "majority", "super_majority", "no_consensus"
    dissenting_reasons: List[str] = field(default_factory=list)


# ======================
# LNN Neural Engine
# ======================

class LiquidNeuralEngine(nn.Module):
    """
    Liquid Neural Network for adaptive decision making.
    
    Key features:
    - Adaptive time constants
    - Sparse connections for efficiency
    - Mixed precision training
    - Real-time adaptation
    """
    
    def __init__(
        self,
        input_size: int = 256,
        hidden_sizes: List[int] = None,
        output_size: int = 64,
        sparsity: float = 0.8,
        device: str = "cuda" if torch.cuda.is_available() else "cpu"
    ):
        super().__init__()
        self.device = torch.device(device)
        self.sparsity = sparsity
        
        if hidden_sizes is None:
            hidden_sizes = [128, 96, 64]
        
        # Build liquid layers
        layers = []
        prev_size = input_size
        
        for hidden_size in hidden_sizes:
            layers.append(self._create_liquid_layer(prev_size, hidden_size))
            prev_size = hidden_size
        
        self.liquid_layers = nn.ModuleList(layers)
        
        # Output layer
        self.output_layer = nn.Linear(prev_size, output_size)
        
        # Adaptive time constants
        self.time_constants = nn.Parameter(torch.ones(len(hidden_sizes)) * 0.1)
        
        # Move to device
        self.to(self.device)
        
    def _create_liquid_layer(self, input_size: int, output_size: int) -> nn.Module:
        """Create a liquid layer with sparse connections"""
        if self.sparsity < 1.0:
            # Sparse connections for efficiency
            mask = torch.rand(output_size, input_size) > self.sparsity
            layer = nn.Linear(input_size, output_size, bias=True)
            # Apply sparsity mask
            with torch.no_grad():
                layer.weight.data *= mask.float().to(self.device)
            return layer
        else:
            return nn.Linear(input_size, output_size)
    
    def forward(self, x: torch.Tensor, dt: float = 0.01) -> torch.Tensor:
        """Forward pass with liquid dynamics"""
        batch_size = x.shape[0]
        
        # Initialize hidden states
        hidden_states = []
        h = x
        
        # Process through liquid layers
        for i, layer in enumerate(self.liquid_layers):
            # Liquid dynamics: dh/dt = -h/tau + f(Wx + b)
            tau = self.time_constants[i]
            h_new = layer(h)
            
            # Exponential decay with time constant
            decay = torch.exp(-dt / tau)
            # Use h_new dimensions for next layer
            h = decay * h_new + (1 - decay) * torch.tanh(h_new)
            
            hidden_states.append(h)
        
        # Output projection
        output = self.output_layer(h)
        
        return output, hidden_states


# ======================
# Byzantine Consensus
# ======================

class ByzantineConsensus:
    """
    Byzantine fault-tolerant consensus for multi-agent decisions.
    
    Features:
    - Handles up to 1/3 malicious agents
    - Weighted voting based on reputation
    - Automatic outlier detection
    """
    
    def __init__(
        self,
        min_agents: int = 3,
        byzantine_threshold: float = 0.33,
        super_majority_threshold: float = 0.67
    ):
        self.min_agents = min_agents
        self.byzantine_threshold = byzantine_threshold
        self.super_majority_threshold = super_majority_threshold
        self.agent_reputations: Dict[str, float] = {}
        
    async def reach_consensus(
        self,
        votes: List[CouncilVote],
        topic: str = "general"
    ) -> ConsensusResult:
        """Reach Byzantine consensus on votes"""
        
        if len(votes) < self.min_agents:
            raise ValueError(f"Need at least {self.min_agents} votes for consensus")
        
        # Filter out potential Byzantine agents
        valid_votes = self._filter_byzantine_votes(votes)
        
        # Weight votes by reputation
        weighted_votes = self._apply_reputation_weights(valid_votes)
        
        # Count weighted votes
        vote_counts = {}
        total_weight = 0
        
        for vote, weight in weighted_votes:
            decision = vote.decision
            vote_counts[decision] = vote_counts.get(decision, 0) + weight
            total_weight += weight
        
        # Determine consensus
        max_decision = max(vote_counts.items(), key=lambda x: x[1])
        consensus_ratio = max_decision[1] / total_weight
        
        # Determine consensus type
        if consensus_ratio >= 0.99:
            consensus_type = "unanimous"
        elif consensus_ratio >= self.super_majority_threshold:
            consensus_type = "super_majority"
        elif consensus_ratio >= 0.5:
            consensus_type = "majority"
        else:
            consensus_type = "no_consensus"
        
        # Collect dissenting reasons
        dissenting_reasons = []
        for vote in valid_votes:
            if vote.decision != max_decision[0]:
                dissenting_reasons.append(f"{vote.agent_id}: {vote.reasoning}")
        
        # Update reputations based on consensus
        self._update_reputations(votes, max_decision[0])
        
        return ConsensusResult(
            final_decision=max_decision[0],
            consensus_confidence=consensus_ratio,
            votes=votes,
            consensus_type=consensus_type,
            dissenting_reasons=dissenting_reasons[:5]  # Top 5 dissenting reasons
        )
    
    def _filter_byzantine_votes(self, votes: List[CouncilVote]) -> List[CouncilVote]:
        """Filter out potential Byzantine (malicious) votes"""
        # Simple outlier detection based on confidence
        confidences = [v.confidence for v in votes]
        mean_conf = np.mean(confidences)
        std_conf = np.std(confidences)
        
        valid_votes = []
        for vote in votes:
            # Flag votes with extremely low confidence or > 2 std deviations
            if vote.confidence > 0.1 and abs(vote.confidence - mean_conf) <= 2 * std_conf:
                valid_votes.append(vote)
            else:
                logger.warning(f"Filtered potential Byzantine vote from {vote.agent_id}")
        
        return valid_votes
    
    def _apply_reputation_weights(
        self,
        votes: List[CouncilVote]
    ) -> List[Tuple[CouncilVote, float]]:
        """Apply reputation-based weights to votes"""
        weighted_votes = []
        
        for vote in votes:
            # Get or initialize reputation
            reputation = self.agent_reputations.get(vote.agent_id, 0.5)
            
            # Weight combines confidence and reputation
            weight = vote.confidence * (0.5 + 0.5 * reputation)
            weighted_votes.append((vote, weight))
        
        return weighted_votes
    
    def _update_reputations(self, votes: List[CouncilVote], consensus_decision: VoteDecision):
        """Update agent reputations based on consensus alignment"""
        for vote in votes:
            current_rep = self.agent_reputations.get(vote.agent_id, 0.5)
            
            # Increase reputation for consensus alignment, decrease for dissent
            if vote.decision == consensus_decision:
                new_rep = min(1.0, current_rep + 0.01)
            else:
                new_rep = max(0.0, current_rep - 0.01)
            
            self.agent_reputations[vote.agent_id] = new_rep


# ======================
# Neural Council Agent
# ======================

class LNNCouncilAgent:
    """
    Multi-agent council with neural decision making.
    
    This agent can participate in council decisions using:
    - Liquid neural networks for adaptation
    - Byzantine consensus for reliability
    - Transformer reasoning for explanations
    """
    
    def __init__(
        self,
        agent_id: str,
        lnn_engine: Optional[LiquidNeuralEngine] = None,
        capabilities: List[str] = None
    ):
        self.agent_id = agent_id
        self.lnn_engine = lnn_engine or LiquidNeuralEngine()
        self.capabilities = capabilities or ["general_reasoning"]
        self.decision_history = []
        
    async def make_decision(
        self,
        request: Dict[str, Any],
        context: Optional[Dict[str, Any]] = None
    ) -> CouncilVote:
        """Make a decision on a request"""
        
        # Extract features from request
        features = self._extract_features(request, context)
        
        # Neural inference
        with torch.no_grad():
            features_tensor = torch.tensor(features, dtype=torch.float32)
            features_tensor = features_tensor.unsqueeze(0).to(self.lnn_engine.device)
            
            output, hidden_states = self.lnn_engine(features_tensor)
            
            # Convert output to decision
            decision_logits = output[0][:5]  # First 5 outputs for decisions
            decision_probs = F.softmax(decision_logits, dim=0)
            
            decision_idx = torch.argmax(decision_probs).item()
            confidence = decision_probs[decision_idx].item()
        
        # Map to decision
        decision_map = {
            0: VoteDecision.APPROVE,
            1: VoteDecision.REJECT,
            2: VoteDecision.ABSTAIN,
            3: VoteDecision.DELEGATE,
            4: VoteDecision.ESCALATE
        }
        decision = decision_map.get(decision_idx, VoteDecision.ABSTAIN)
        
        # Generate reasoning
        reasoning = self._generate_reasoning(request, decision, confidence, hidden_states)
        
        # Create vote
        vote = CouncilVote(
            agent_id=self.agent_id,
            decision=decision,
            confidence=VoteConfidence(confidence),
            reasoning=reasoning,
            evidence=self._collect_evidence(request, context)
        )
        
        # Store in history
        self.decision_history.append(vote)
        
        return vote
    
    def _extract_features(
        self,
        request: Dict[str, Any],
        context: Optional[Dict[str, Any]]
    ) -> List[float]:
        """Extract numerical features from request"""
        features = []
        
        # Request features
        features.append(float(request.get("priority", 5)) / 10.0)
        features.append(float(request.get("urgency", 0.5)))
        features.append(float(len(request.get("requirements", []))) / 10.0)
        
        # Context features
        if context:
            features.append(float(context.get("risk_score", 0.5)))
            features.append(float(context.get("resource_availability", 0.5)))
            features.append(float(len(context.get("similar_requests", []))) / 10.0)
        else:
            features.extend([0.5, 0.5, 0.0])
        
        # Pad to expected input size
        while len(features) < 256:
            features.append(0.0)
        
        return features[:256]
    
    def _generate_reasoning(
        self,
        request: Dict[str, Any],
        decision: VoteDecision,
        confidence: float,
        hidden_states: List[torch.Tensor]
    ) -> str:
        """Generate human-readable reasoning"""
        
        # Analyze hidden states for key factors
        factors = []
        
        if confidence > 0.8:
            factors.append("high confidence")
        elif confidence < 0.5:
            factors.append("low confidence")
        
        if request.get("priority", 5) > 7:
            factors.append("high priority request")
        
        # Build reasoning
        reasoning = f"Decision: {decision.value} based on {', '.join(factors)}"
        
        if decision == VoteDecision.APPROVE:
            reasoning += ". Request meets requirements."
        elif decision == VoteDecision.REJECT:
            reasoning += ". Request has significant issues."
        elif decision == VoteDecision.ESCALATE:
            reasoning += ". Request requires higher-level review."
        
        return reasoning
    
    def _collect_evidence(
        self,
        request: Dict[str, Any],
        context: Optional[Dict[str, Any]]
    ) -> List[Dict[str, Any]]:
        """Collect supporting evidence"""
        evidence = []
        
        # Add request analysis
        evidence.append({
            "type": "request_analysis",
            "priority": request.get("priority", 5),
            "requirements_count": len(request.get("requirements", []))
        })
        
        # Add context if available
        if context:
            evidence.append({
                "type": "context_analysis",
                "risk_score": context.get("risk_score", 0.5),
                "resource_availability": context.get("resource_availability", 0.5)
            })
        
        return evidence


# ======================
# Council Orchestrator
# ======================

class LNNCouncilOrchestrator:
    """
    Orchestrates multi-agent council decisions.
    
    Features:
    - Manages multiple LNN agents
    - Coordinates voting
    - Applies Byzantine consensus
    - Tracks performance metrics
    """
    
    def __init__(
        self,
        min_agents: int = 3,
        max_agents: int = 10
    ):
        self.min_agents = min_agents
        self.max_agents = max_agents
        self.agents: Dict[str, LNNCouncilAgent] = {}
        self.consensus = ByzantineConsensus(min_agents=min_agents)
        self.decision_count = 0
        self.metrics = {
            "total_decisions": 0,
            "consensus_reached": 0,
            "average_confidence": 0.0,
            "decision_times": []
        }
        
    def add_agent(self, agent: LNNCouncilAgent):
        """Add an agent to the council"""
        if len(self.agents) >= self.max_agents:
            raise ValueError(f"Council full (max {self.max_agents} agents)")
        self.agents[agent.agent_id] = agent
        logger.info(f"Added agent {agent.agent_id} to council")
        
    async def make_council_decision(
        self,
        request: Dict[str, Any],
        context: Optional[Dict[str, Any]] = None,
        required_capabilities: Optional[List[str]] = None
    ) -> ConsensusResult:
        """Make a council decision using all capable agents"""
        
        start_time = datetime.now(timezone.utc)
        
        # Select capable agents
        capable_agents = self._select_capable_agents(required_capabilities)
        
        if len(capable_agents) < self.min_agents:
            raise ValueError(
                f"Not enough capable agents ({len(capable_agents)} < {self.min_agents})"
            )
        
        # Collect votes in parallel
        vote_tasks = []
        for agent in capable_agents:
            task = asyncio.create_task(agent.make_decision(request, context))
            vote_tasks.append(task)
        
        votes = await asyncio.gather(*vote_tasks)
        
        # Reach consensus
        consensus = await self.consensus.reach_consensus(votes, topic=request.get("type", "general"))
        
        # Update metrics
        self._update_metrics(consensus, start_time)
        
        logger.info(
            f"Council decision: {consensus.final_decision.value}",
            confidence=consensus.consensus_confidence,
            consensus_type=consensus.consensus_type,
            votes=len(votes)
        )
        
        return consensus
    
    def _select_capable_agents(
        self,
        required_capabilities: Optional[List[str]]
    ) -> List[LNNCouncilAgent]:
        """Select agents with required capabilities"""
        if not required_capabilities:
            return list(self.agents.values())
        
        capable_agents = []
        for agent in self.agents.values():
            if any(cap in agent.capabilities for cap in required_capabilities):
                capable_agents.append(agent)
        
        return capable_agents
    
    def _update_metrics(self, consensus: ConsensusResult, start_time: datetime):
        """Update performance metrics"""
        self.metrics["total_decisions"] += 1
        
        if consensus.consensus_type != "no_consensus":
            self.metrics["consensus_reached"] += 1
        
        # Update average confidence
        avg_conf = np.mean([v.confidence for v in consensus.votes])
        current_avg = self.metrics["average_confidence"]
        n = self.metrics["total_decisions"]
        self.metrics["average_confidence"] = (current_avg * (n - 1) + avg_conf) / n
        
        # Track decision time
        decision_time = (datetime.now(timezone.utc) - start_time).total_seconds()
        self.metrics["decision_times"].append(decision_time)
        
        # Keep only last 100 decision times
        if len(self.metrics["decision_times"]) > 100:
            self.metrics["decision_times"] = self.metrics["decision_times"][-100:]
    
    def get_metrics(self) -> Dict[str, Any]:
        """Get performance metrics"""
        metrics = self.metrics.copy()
        
        if self.metrics["decision_times"]:
            metrics["avg_decision_time_s"] = np.mean(self.metrics["decision_times"])
            metrics["p95_decision_time_s"] = np.percentile(self.metrics["decision_times"], 95)
        
        metrics["consensus_rate"] = (
            self.metrics["consensus_reached"] / max(1, self.metrics["total_decisions"])
        )
        
        return metrics


# ======================
# Integration Helper
# ======================

def create_lnn_council(
    num_agents: int = 5,
    agent_capabilities: Optional[Dict[str, List[str]]] = None
) -> LNNCouncilOrchestrator:
    """Create a ready-to-use LNN council"""
    
    orchestrator = LNNCouncilOrchestrator()
    
    # Create agents with different capabilities
    default_capabilities = {
        "agent_0": ["general_reasoning", "risk_assessment"],
        "agent_1": ["general_reasoning", "cost_optimization"],
        "agent_2": ["general_reasoning", "compliance_check"],
        "agent_3": ["general_reasoning", "resource_management"],
        "agent_4": ["general_reasoning", "performance_analysis"]
    }
    
    capabilities_map = agent_capabilities or default_capabilities
    
    for i in range(num_agents):
        agent_id = f"agent_{i}"
        capabilities = capabilities_map.get(agent_id, ["general_reasoning"])
        
        # Create agent with its own LNN
        agent = LNNCouncilAgent(
            agent_id=agent_id,
            lnn_engine=LiquidNeuralEngine(),
            capabilities=capabilities
        )
        
        orchestrator.add_agent(agent)
    
    return orchestrator


# Example usage for neural router enhancement
async def enhance_neural_router_with_council(
    router_request: Dict[str, Any],
    council: LNNCouncilOrchestrator
) -> Dict[str, Any]:
    """
    Use LNN council to enhance neural router decisions.
    
    Multiple agents vote on:
    - Which model to use
    - Routing strategy
    - Fallback options
    """
    
    # Transform router request for council
    council_request = {
        "type": "model_selection",
        "priority": router_request.get("priority", 5),
        "requirements": [
            f"latency_ms < {router_request.get('max_latency', 1000)}",
            f"cost_per_token < {router_request.get('max_cost', 0.01)}",
            f"context_length >= {router_request.get('context_length', 4096)}"
        ],
        "models": router_request.get("available_models", []),
        "request_type": router_request.get("task_type", "general")
    }
    
    # Get council decision
    consensus = await council.make_council_decision(
        request=council_request,
        context={
            "current_load": router_request.get("system_load", 0.5),
            "failure_history": router_request.get("recent_failures", []),
            "performance_metrics": router_request.get("model_metrics", {})
        },
        required_capabilities=["general_reasoning", "performance_analysis"]
    )
    
    # Extract routing decision
    if consensus.final_decision == VoteDecision.APPROVE:
        # Use primary model choice
        selected_model = council_request["models"][0] if council_request["models"] else "default"
    elif consensus.final_decision == VoteDecision.DELEGATE:
        # Use fallback chain
        selected_model = "fallback_chain"
    else:
        # Use conservative default
        selected_model = "gpt-3.5-turbo"
    
    return {
        "selected_model": selected_model,
        "confidence": consensus.consensus_confidence,
        "consensus_type": consensus.consensus_type,
        "reasoning": [v.reasoning for v in consensus.votes[:3]]  # Top 3 reasons
    }