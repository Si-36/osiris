# ğŸ§¹ CLEANUP PLAN: What to Remove and Keep

## ğŸ“Š Current State
- **684 Python files** total
- **~300 files** already transformed/consolidated
- **~400 files** remaining to process

## ğŸ—‘ï¸ IMMEDIATE CLEANUP NEEDED

### 1. **Enterprise Folder (Mem0/GraphRAG originals)**
Since we've extracted the best parts:
- âœ… KEEP: Our extractions in `memory/enhancements/` and `memory/graph/`
- âŒ REMOVE: `enterprise/mem0_*` folders (already extracted)
- âŒ REMOVE: `enterprise/knowledge_graph.py` (we have GraphRAG now)
- âš ï¸ REVIEW: Other enterprise files for unique features

### 2. **LNN Duplicates**
We extracted council to `agents/lnn_council.py`:
- âŒ REMOVE: `agents/council/lnn/` (79 files! - already extracted)
- âš ï¸ REVIEW: `lnn/` folder - might have other LNN implementations
  - `core.py` (706 lines) - check if different from council
  - `advanced_lnn_system.py` (848 lines) - check for unique features

### 3. **Old Memory Files**
Keep our new structure, remove old:
- âŒ REMOVE: Old memory files that duplicate our new system
- âœ… KEEP: Our new `memory/` structure with enhancements

### 4. **TDA Legacy (Already Done)**
- âœ… Already moved 21 files to `tda/legacy/`

### 5. **Multiple "Unified" Systems**
Too many entry points:
- `unified_brain.py` (446 lines)
- `production_system_2025.py` (699 lines)
- `ultra_deep_2025.py` (439 lines)
- `enhanced_system_2025.py` (344 lines)
- âš ï¸ NEED TO: Consolidate to ONE main entry point

## ğŸ“ FILES TO DELETE NOW

```bash
# Enterprise duplicates (we extracted Mem0 and GraphRAG)
rm -rf core/src/aura_intelligence/enterprise/mem0_hot/
rm -rf core/src/aura_intelligence/enterprise/mem0_semantic/
rm -rf core/src/aura_intelligence/enterprise/mem0_search/
rm core/src/aura_intelligence/enterprise/knowledge_graph.py

# LNN council (we extracted to agents/lnn_council.py)
rm -rf core/src/aura_intelligence/agents/council/lnn/

# Old provider adapter attempt
rm core/src/aura_intelligence/neural/provider_adapters_simple.py

# Backup files
find core/src/aura_intelligence -name "*.bak" -delete
```

## ğŸ“ FILES TO ARCHIVE (Move to legacy/)

```bash
# Research/experimental files
mkdir -p core/src/aura_intelligence/legacy/research/

# Move research files
mv core/src/aura_intelligence/research_2025/ legacy/research/
mv core/src/aura_intelligence/bio_homeostatic/ legacy/research/
mv core/src/aura_intelligence/chaos/ legacy/research/
```

## âœ… FILES TO KEEP (Our Work)

### Phase 1 & 2 Creations:
```
neural/
â”œâ”€â”€ model_router.py âœ…
â”œâ”€â”€ provider_adapters.py âœ…
â”œâ”€â”€ adaptive_routing_engine.py âœ…
â”œâ”€â”€ cache_manager.py âœ…
â”œâ”€â”€ fallback_chain.py âœ…
â”œâ”€â”€ cost_optimizer.py âœ…
â”œâ”€â”€ load_balancer.py âœ…
â”œâ”€â”€ performance_tracker.py âœ…
â””â”€â”€ context_manager.py âœ…

tda/
â”œâ”€â”€ agent_topology.py âœ…
â”œâ”€â”€ algorithms.py âœ…
â”œâ”€â”€ realtime_monitor.py âœ…
â”œâ”€â”€ enhanced_topology.py âœ…
â””â”€â”€ legacy/ (archived) âœ…

memory/
â”œâ”€â”€ core/
â”‚   â”œâ”€â”€ memory_api.py âœ…
â”‚   â”œâ”€â”€ topology_adapter.py âœ…
â”‚   â””â”€â”€ causal_tracker.py âœ…
â”œâ”€â”€ routing/
â”‚   â””â”€â”€ hierarchical_router.py âœ…
â”œâ”€â”€ storage/
â”‚   â””â”€â”€ tier_manager.py âœ…
â”œâ”€â”€ operations/
â”‚   â””â”€â”€ monitoring.py âœ…
â”œâ”€â”€ enhancements/
â”‚   â””â”€â”€ mem0_integration.py âœ…
â”œâ”€â”€ graph/
â”‚   â””â”€â”€ graphrag_knowledge.py âœ…
â””â”€â”€ hardware/
    â””â”€â”€ hardware_tier_manager.py âœ…

orchestration/
â”œâ”€â”€ unified_orchestration_engine.py âœ…
â””â”€â”€ gpu/
    â””â”€â”€ gpu_workflow_integration.py âœ…

agents/
â”œâ”€â”€ lnn_council.py âœ…
â”œâ”€â”€ agent_core.py âœ…
â””â”€â”€ agent_templates.py âœ…

persistence/
â””â”€â”€ lakehouse_core.py âœ…
```

## ğŸ”¢ Cleanup Impact

**Before Cleanup:**
- 684 Python files
- Many duplicates
- Confusing structure

**After Cleanup:**
- ~550 Python files (remove ~134 duplicates)
- Clear structure
- No confusion about what to use

## ğŸ¯ Next Steps After Cleanup

1. **Complete Integration**
   - Connect Iceberg to Memory system
   - Wire Mem0 enhancements
   - Test GraphRAG with real data

2. **Continue Transformation**
   - Phase 3: swarm/, distributed/, consensus/
   - Phase 4: Final consolidation

3. **Create Single Entry Point**
   - One main.py or aura_system.py
   - Clear API
   - Deprecate all "unified" files

## âš ï¸ IMPORTANT NOTES

1. **Before deleting:** Make sure we've extracted all valuable code
2. **Create backups:** `cp -r core/src/aura_intelligence core/src/aura_intelligence.backup`
3. **Test after cleanup:** Run our integration tests
4. **Document deletions:** Keep track of what was removed and why

## ğŸ“ Cleanup Commands

```bash
# 1. Backup first
cp -r core/src/aura_intelligence core/src/aura_intelligence.backup

# 2. Remove duplicates
rm -rf core/src/aura_intelligence/enterprise/mem0_*
rm -rf core/src/aura_intelligence/agents/council/lnn/
rm core/src/aura_intelligence/neural/provider_adapters_simple.py

# 3. Clean backup files
find core/src/aura_intelligence -name "*.bak" -delete

# 4. Archive research
mkdir -p core/src/aura_intelligence/legacy/research/
mv core/src/aura_intelligence/research_2025/ core/src/aura_intelligence/legacy/research/

# 5. Verify
find core/src/aura_intelligence -type f -name "*.py" | wc -l
# Should show ~550 files
```

This cleanup will make the codebase much cleaner and easier to navigate!