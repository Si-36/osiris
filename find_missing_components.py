#!/usr/bin/env python3
"""
Find specific missing components and issues in the AURA project
"""

import json
from pathlib import Path
import re

def analyze_report():
    # Load the report
    with open('/workspace/project_index_report.json', 'r') as f:
        report = json.load(f)
    
    print("üîç DETAILED ANALYSIS OF MISSING COMPONENTS")
    print("=" * 80)
    
    # 1. Missing critical dependencies
    print("\n1Ô∏è‚É£ MISSING CRITICAL DEPENDENCIES:")
    expected_deps = {
        'prometheus-client': 'Monitoring metrics',
        'opentelemetry': 'Distributed tracing',
        'grpcio': 'gRPC communication',
        'celery': 'Task queue',
        'elasticsearch': 'Search and analytics',
        'minio': 'Object storage',
        'confluent-kafka': 'Kafka client',
        'pytest': 'Testing framework',
        'black': 'Code formatter',
        'mypy': 'Type checking'
    }
    
    current_deps = set(d.lower() for d in report['external_dependencies'])
    for dep, purpose in expected_deps.items():
        if dep not in current_deps and not any(dep in d for d in current_deps):
            print(f"   ‚ùå {dep}: {purpose}")
    
    # 2. Check for incomplete implementations
    print("\n2Ô∏è‚É£ INCOMPLETE IMPLEMENTATIONS:")
    dummy_by_file = {}
    for dummy in report['dummy_implementations']:
        file = dummy['file']
        if file not in dummy_by_file:
            dummy_by_file[file] = []
        dummy_by_file[file].append(dummy['function'])
    
    for file, functions in sorted(dummy_by_file.items())[:10]:
        if len(functions) > 1:
            print(f"   üìÅ {file.split('/')[-2:]}: {len(functions)} dummy functions")
    
    # 3. Import errors analysis
    print("\n3Ô∏è‚É£ IMPORT ERRORS TO FIX:")
    for error in report['import_errors'][:10]:
        print(f"   üî¥ {error['file'].split('/')[-1]}: {error['error']}")
    
    # 4. Missing infrastructure
    print("\n4Ô∏è‚É£ MISSING INFRASTRUCTURE:")
    
    # Check for Kubernetes manifests
    k8s_files = list(Path('/workspace').rglob('*.yaml'))
    k8s_manifests = [f for f in k8s_files if any(k in str(f) for k in ['deployment', 'service', 'configmap'])]
    if len(k8s_manifests) < 5:
        print(f"   ‚ùå Kubernetes manifests: Only {len(k8s_manifests)} found")
    
    # Check for Terraform files
    terraform_files = list(Path('/workspace').rglob('*.tf'))
    if not terraform_files:
        print("   ‚ùå Terraform configuration: No .tf files found")
    
    # Check for monitoring
    if not any('prometheus' in str(f) or 'grafana' in str(f) for f in report['config_files']):
        print("   ‚ùå Monitoring configuration: No Prometheus/Grafana setup")
    
    # 5. Missing tests
    print("\n5Ô∏è‚É£ TEST COVERAGE ANALYSIS:")
    src_files = set()
    test_files = set()
    
    for f in Path('/workspace/core/src').rglob('*.py'):
        if '__pycache__' not in str(f) and not f.name.startswith('test_'):
            src_files.add(f.stem)
    
    for f in report['test_files']:
        if 'test_' in f:
            # Extract what it's testing
            name = Path(f).stem.replace('test_', '')
            test_files.add(name)
    
    untested = src_files - test_files
    coverage = len(test_files) / len(src_files) if src_files else 0
    
    print(f"   üìä Test coverage: {coverage:.1%}")
    print(f"   ‚ùå Untested modules: {len(untested)}")
    print(f"   Examples: {list(untested)[:5]}")
    
    # 6. Security issues
    print("\n6Ô∏è‚É£ SECURITY ISSUES:")
    
    # Check for pickle usage (already fixed some)
    pickle_files = []
    for f in Path('/workspace').rglob('*.py'):
        if '__pycache__' not in str(f):
            try:
                with open(f, 'r') as file:
                    if 'pickle' in file.read():
                        pickle_files.append(str(f))
            except:
                pass
    
    if pickle_files:
        print(f"   ‚ö†Ô∏è  Files still using pickle: {len(pickle_files)}")
        for f in pickle_files[:3]:
            print(f"      - {f}")
    
    # 7. Production readiness
    print("\n7Ô∏è‚É£ PRODUCTION READINESS:")
    
    missing_prod = []
    
    # Check for health checks
    if not any('health' in e['function'] for e in report['api_endpoints']):
        missing_prod.append("Health check endpoints")
    
    # Check for rate limiting
    if not any('ratelimit' in d.lower() for d in report['external_dependencies']):
        missing_prod.append("Rate limiting")
    
    # Check for circuit breakers
    if not any('circuit' in str(f).lower() for f in Path('/workspace').rglob('*.py')):
        missing_prod.append("Circuit breakers")
    
    # Check for feature flags
    if not any('feature' in str(f).lower() and 'flag' in str(f).lower() for f in Path('/workspace').rglob('*.py')):
        missing_prod.append("Feature flags")
    
    for item in missing_prod:
        print(f"   ‚ùå {item}")
    
    # 8. Documentation
    print("\n8Ô∏è‚É£ DOCUMENTATION STATUS:")
    
    docs = list(Path('/workspace').rglob('*.md'))
    api_docs = [d for d in docs if 'api' in str(d).lower()]
    arch_docs = [d for d in docs if 'architecture' in str(d).lower()]
    
    print(f"   üìÑ Total docs: {len(docs)}")
    print(f"   {'‚úÖ' if api_docs else '‚ùå'} API documentation: {len(api_docs)} files")
    print(f"   {'‚úÖ' if arch_docs else '‚ùå'} Architecture docs: {len(arch_docs)} files")
    
    # Check for inline documentation
    no_docstring = 0
    total_functions = 0
    for impl in report['real_implementations']:
        total_functions += 1
        # This is a rough estimate
        if impl['lines'] < 3:
            no_docstring += 1
    
    docstring_coverage = 1 - (no_docstring / total_functions) if total_functions else 0
    print(f"   üìù Docstring coverage: ~{docstring_coverage:.1%}")

if __name__ == "__main__":
    analyze_report()