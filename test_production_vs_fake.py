#!/usr/bin/env python3
"""
Production vs Fake System Comparison Test
Shows the difference between old fake implementations and new production systems
"""

import asyncio
import time
import sys
from pathlib import Path

# Add to path
sys.path.insert(0, str(Path(__file__).parent / "core" / "src"))

async def test_production_actor_system():
    """Test production Ray actor system"""
    print("üöÄ Testing Production Actor System...")
    
    try:
        from aura_intelligence.distributed.actor_system import get_actor_system
        
        system = get_actor_system()
        
        # Test distributed processing
        test_data = {
            'values': [0.1, 0.2, 0.3, 0.4, 0.5] * 50,  # 250 values for neural processing
            'points': [[i, i+1] for i in range(20)]
        }
        
        # Test neural component
        neural_result = await system.process_distributed('neural_lnn_001', test_data)
        print(f"  ‚úÖ Neural processing: {neural_result.get('success', False)}")
        if neural_result.get('success'):
            result_data = neural_result.get('result', {})
            print(f"    - Model parameters: {result_data.get('parameters', 0)}")
            print(f"    - Processing time: {neural_result.get('processing_time_ms', 0):.2f}ms")
        
        # Test TDA component
        tda_result = await system.process_distributed('tda_topology_001', test_data)
        print(f"  ‚úÖ TDA processing: {tda_result.get('success', False)}")
        if tda_result.get('success'):
            result_data = tda_result.get('result', {})
            print(f"    - Betti numbers: {result_data.get('betti_numbers', [])}")
            print(f"    - Library: {result_data.get('library', 'unknown')}")
        
        # Test batch processing
        batch_tasks = [
            ('neural_001', test_data),
            ('neural_002', test_data),
            ('tda_001', test_data),
            ('memory_001', {'key': 'test', 'value': 'data'})
        ]
        
        batch_results = await system.batch_process(batch_tasks)
        successful_batch = sum(1 for r in batch_results if r.get('success', False))
        print(f"  ‚úÖ Batch processing: {successful_batch}/{len(batch_tasks)} successful")
        
        # Get cluster status
        status = await system.get_cluster_status()
        if 'error' not in status:
            print(f"  üìä Cluster status:")
            print(f"    - Total actors: {status.get('total_actors', 0)}")
            print(f"    - Healthy actors: {status.get('healthy_actors', 0)}")
            print(f"    - CPU utilization: {status.get('cpu_utilization', 0):.1%}")
            print(f"    - Ray version: {status.get('ray_version', 'unknown')}")
        
        return neural_result.get('success', False) and tda_result.get('success', False)
        
    except Exception as e:
        print(f"  ‚ùå Production actor system failed: {e}")
        return False

async def test_production_dpo_system():
    """Test production DPO system"""
    print("üß† Testing Production DPO System...")
    
    try:
        from aura_intelligence.dpo.production_dpo import get_production_dpo, PreferenceRecord
        
        dpo = get_production_dpo()
        
        # Create sample action history for offline mining
        action_history = [
            {
                'type': 'neural_processing',
                'confidence': 0.9,
                'success': 1.0,
                'processing_time': 0.05,
                'context': {'system_load': 0.3, 'user_safety_level': 0.9}
            },
            {
                'type': 'neural_processing', 
                'confidence': 0.6,
                'success': 0.7,
                'processing_time': 0.12,
                'context': {'system_load': 0.3, 'user_safety_level': 0.9}
            },
            {
                'type': 'memory_operation',
                'confidence': 0.8,
                'success': 0.95,
                'processing_time': 0.02,
                'context': {'system_load': 0.5, 'user_safety_level': 0.8}
            }
        ]
        
        # Mine preferences offline
        preferences = dpo.mine_preferences_offline(action_history)
        print(f"  ‚úÖ Offline preference mining: {len(preferences)} preferences found")
        
        # Add preferences to training buffer
        for pref in preferences:
            dpo.add_preference(pref)
        
        # Add some manual preferences for testing
        manual_pref = PreferenceRecord(
            chosen_action={
                'type': 'safe_action',
                'confidence': 0.9,
                'success': 1.0,
                'context': {'safety_critical': True}
            },
            rejected_action={
                'type': 'risky_action', 
                'confidence': 0.7,
                'success': 0.6,
                'context': {'safety_critical': True}
            },
            context={'safety_critical': True},
            preference_strength=0.8,
            timestamp=time.time(),
            source='manual_testing'
        )
        dpo.add_preference(manual_pref)
        
        # Test constitutional safety checker
        test_action = {
            'type': 'system_modification',
            'confidence': 0.8,
            'description': 'Optimize system performance'
        }
        test_context = {
            'user_safety_level': 0.9,
            'system_load': 0.4
        }
        
        safety_result = dpo.safety_checker.evaluate_safety(test_action, test_context)
        print(f"  üõ°Ô∏è  Constitutional safety check:")
        print(f"    - Safety score: {safety_result['safety_score']:.3f}")
        print(f"    - Safe: {safety_result['safe']}")
        print(f"    - Violations: {len(safety_result['violations'])}")
        print(f"    - Version: {safety_result['constitutional_version']}")
        
        # Test training if we have enough data
        if len(dpo.preference_buffer) >= 4:
            training_result = await dpo.train_batch(batch_size=4)
            print(f"  üéØ DPO training:")
            print(f"    - Status: {training_result['status']}")
            if training_result['status'] == 'training_complete':
                print(f"    - Loss: {training_result['loss']:.4f}")
                print(f"    - Accuracy: {training_result['preference_accuracy']:.3f}")
                print(f"    - Updates: {training_result['total_updates']}")
        
        # Get training stats
        stats = dpo.get_training_stats()
        print(f"  üìä Training statistics:")
        print(f"    - Buffer size: {stats['preference_buffer_size']}")
        print(f"    - Model parameters: {stats['model_parameters']:,}")
        print(f"    - Constitutional violations: {stats['constitutional_violations']}")
        print(f"    - DPO beta: {stats['dpo_beta']}")
        
        return len(preferences) > 0 and safety_result['constitutional_version'] == '3.0'
        
    except Exception as e:
        print(f"  ‚ùå Production DPO system failed: {e}")
        return False

async def test_fake_vs_production_comparison():
    """Compare fake vs production implementations"""
    print("‚öñÔ∏è  Comparing Fake vs Production Systems...")
    
    try:
        # Test old fake component registry
        from aura_intelligence.components.registry import get_component_registry
        fake_registry = get_component_registry()
        fake_stats = fake_registry.get_component_stats()
        
        print(f"  üìä Fake Registry:")
        print(f"    - Total components: {fake_stats['total_components']}")
        print(f"    - Implementation: String-based definitions")
        print(f"    - Processing: Mock/simulated")
        print(f"    - Real computation: ‚ùå No")
        
        # Test production actor system
        from aura_intelligence.distributed.actor_system import get_actor_system
        prod_system = get_actor_system()
        
        if prod_system.initialize():
            prod_status = await prod_system.get_cluster_status()
            
            print(f"  üöÄ Production System:")
            print(f"    - Ray actors: {prod_status.get('total_actors', 0)}")
            print(f"    - Implementation: Real distributed processing")
            print(f"    - Processing: Actual PyTorch/GUDHI/Redis")
            print(f"    - Real computation: ‚úÖ Yes")
            print(f"    - Resource allocation: {prod_status.get('cluster_resources', {})}")
        
        # Performance comparison
        print(f"  ‚ö° Performance Comparison:")
        
        # Fake processing (just returns mock data)
        fake_start = time.perf_counter()
        fake_result = {'mock': True, 'processing_time': 0.001}
        fake_time = (time.perf_counter() - fake_start) * 1000
        
        print(f"    - Fake processing: {fake_time:.3f}ms (mock data)")
        
        # Production processing (real computation)
        if prod_system.initialized:
            prod_start = time.perf_counter()
            prod_result = await prod_system.process_distributed(
                'neural_test', 
                {'values': [0.1] * 256}
            )
            prod_time = (time.perf_counter() - prod_start) * 1000
            
            print(f"    - Production processing: {prod_time:.3f}ms (real computation)")
            print(f"    - Real vs Fake ratio: {prod_time/max(fake_time, 0.001):.1f}x")
        
        return True
        
    except Exception as e:
        print(f"  ‚ùå Comparison failed: {e}")
        return False

async def main():
    """Run comprehensive production vs fake comparison"""
    print("üè≠ PRODUCTION vs FAKE SYSTEM COMPARISON")
    print("=" * 60)
    
    tests = [
        ("Production Actor System", test_production_actor_system),
        ("Production DPO System", test_production_dpo_system),
        ("Fake vs Production Comparison", test_fake_vs_production_comparison)
    ]
    
    results = {}
    passed = 0
    total = len(tests)
    
    for test_name, test_func in tests:
        print(f"\nüß™ {test_name}")
        print("-" * 50)
        
        try:
            start_time = time.perf_counter()
            result = await test_func()
            test_time = (time.perf_counter() - start_time) * 1000
            
            results[test_name] = {
                'passed': result,
                'time_ms': test_time
            }
            
            if result:
                passed += 1
                print(f"‚úÖ PASSED ({test_time:.2f}ms)")
            else:
                print(f"‚ùå FAILED ({test_time:.2f}ms)")
                
        except Exception as e:
            results[test_name] = {
                'passed': False,
                'error': str(e),
                'time_ms': 0
            }
            print(f"üí• CRASHED: {e}")
    
    print("\n" + "=" * 60)
    print(f"üìä FINAL RESULTS: {passed}/{total} TESTS PASSED")
    print(f"üèÜ SUCCESS RATE: {passed/total*100:.1f}%")
    
    print("\nüéØ KEY DIFFERENCES:")
    print("  FAKE SYSTEM:")
    print("    ‚ùå Mock data and random numbers")
    print("    ‚ùå String-based component definitions")
    print("    ‚ùå No real distributed processing")
    print("    ‚ùå No actual ML libraries")
    print("    ‚ùå Simulated performance metrics")
    
    print("\n  PRODUCTION SYSTEM:")
    print("    ‚úÖ Real PyTorch neural networks")
    print("    ‚úÖ Actual GUDHI TDA computation")
    print("    ‚úÖ Ray distributed actors")
    print("    ‚úÖ Constitutional AI 3.0")
    print("    ‚úÖ Real preference learning")
    print("    ‚úÖ Production monitoring")
    
    if passed >= total * 0.8:
        print("\nüéâ PRODUCTION SYSTEM IS SIGNIFICANTLY BETTER!")
        print("   Ready for 2025 deployment with real computation")
    else:
        print("\n‚ö†Ô∏è  PRODUCTION SYSTEM NEEDS MORE WORK")
        print("   Some components still need real implementations")
    
    return passed, total

if __name__ == "__main__":
    asyncio.run(main())